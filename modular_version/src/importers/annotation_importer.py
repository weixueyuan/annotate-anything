#!/usr/bin/env python
"""
ç‰©ä½“å±æ€§æ ‡æ³¨å¯¼å…¥å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰

âš ï¸  å·²è¿‡æ—¶ - å»ºè®®ä½¿ç”¨é€šç”¨å¯¼å…¥å™¨
æ¨èä½¿ç”¨: python -m importers.generic_importer --task annotation

ä½¿ç”¨æ–¹å¼ï¼š
    python -m importers.annotation_importer                    # å¯¼å…¥é»˜è®¤æ–‡ä»¶
    python -m importers.annotation_importer --source data.jsonl  # å¯¼å…¥æŒ‡å®šæ–‡ä»¶
    python -m importers.annotation_importer --clean            # æ¸…ç©ºåå¯¼å…¥
"""

import json
import os
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.db_models import Annotation, get_session, get_engine, Base


class AnnotationImporter:
    """ç‰©ä½“å±æ€§æ ‡æ³¨å¯¼å…¥å™¨"""
    
    # GIF åŸºç¡€è·¯å¾„
    BASE_PATH = "/mnt/data/GRScenes-100/instances/renderings"
    
    def __init__(self):
        self.stats = {'imported': 0, 'updated': 0, 'errors': 0}
    
    def build_gif_path(self, model_id: str) -> str:
        """
        æ ¹æ® model_id æ„å»º GIF è·¯å¾„
        
        æ ¼å¼: type-subtype-category-id
        ä¾‹å¦‚: home-others-mirror-31854b50393738c38b46962840048a04
        """
        parts = model_id.split('-')
        if len(parts) >= 4:
            type_folder = f"{parts[0]}_objects"
            subtype_folder = parts[1]
            category_folder = parts[2]
            model_id_part = parts[3]
            
            gif_path = os.path.join(
                self.BASE_PATH, type_folder, subtype_folder, category_folder,
                "thumbnails/merged_views", model_id_part, f"{model_id_part}_fixed.gif"
            )
            return gif_path
        return ""
    
    def parse_jsonl(self, filepath: str):
        """è§£æJSONLæ–‡ä»¶"""
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        
        records = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    try:
                        data = json.loads(line)
                        records.append(data)
                    except json.JSONDecodeError:
                        continue
        return records
    
    def transform_record(self, model_id: str, attrs: dict) -> dict:
        """è½¬æ¢å•æ¡è®°å½• - ä¿æŒåŸå§‹æ•°æ®å®Œå…¨ä¸€è‡´"""
        # å…ƒæ•°æ®ï¼ˆä»attrsä¸­æå–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”¨é»˜è®¤å€¼ï¼‰
        metadata = {
            'annotated': attrs.get('annotated', False),
            'uid': attrs.get('uid', ''),
            'score': attrs.get('score', 1),
        }
        
        # ä¸šåŠ¡æ•°æ® - ä¿æŒåŸå§‹JSONLä¸­çš„æ‰€æœ‰å­—æ®µ
        business_data = {}
        for key, value in attrs.items():
            # è·³è¿‡å…ƒæ•°æ®å­—æ®µ
            if key in ['annotated', 'uid', 'score']:
                continue
            
            # placement: æ•°ç»„è½¬å­—ç¬¦ä¸²ï¼ˆUIæ˜¾ç¤ºéœ€è¦ï¼‰
            if key == 'placement' and isinstance(value, list):
                business_data[key] = ', '.join(value)
            else:
                # å…¶ä»–å­—æ®µä¿æŒåŸæ ·
                business_data[key] = value
        
        # åªæ·»åŠ  image_urlï¼ˆæ–°å¢å­—æ®µï¼‰
        business_data['image_url'] = self.build_gif_path(model_id)
        
        return metadata, business_data
    
    def import_to_db(self, source: str, db_path: str, clean: bool = False, batch_size: int = 1000):
        """å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“"""
        print(f"\n{'='*60}")
        print(f"å¼€å§‹å¯¼å…¥æ•°æ®")
        print(f"{'='*60}")
        print(f"ğŸ“‚ æ•°æ®æº: {source}")
        print(f"ğŸ—„ï¸  æ•°æ®åº“: {db_path}")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        engine = get_engine(db_path)
        if clean:
            print("ğŸ—‘ï¸  æ¸…ç©ºæ•°æ®åº“...")
            Base.metadata.drop_all(engine)
        Base.metadata.create_all(engine)
        
        session = get_session(db_path)
        
        try:
            print(f"ğŸ“– è§£ææ•°æ®...")
            records = self.parse_jsonl(source)
            print(f"âœ“ æ‰¾åˆ° {len(records)} æ¡è®°å½•")
            
            for idx, record in enumerate(records, 1):
                try:
                    # è·å– model_id å’Œå±æ€§
                    model_id = list(record.keys())[0]
                    attrs = record[model_id]
                    
                    # è½¬æ¢æ•°æ®
                    metadata, business_data = self.transform_record(model_id, attrs)
                    
                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨
                    existing = session.query(Annotation).filter_by(model_id=model_id).first()
                    
                    if existing:
                        # æ›´æ–°
                        existing.annotated = metadata['annotated']
                        existing.uid = metadata['uid']
                        existing.score = metadata['score']
                        existing.data = business_data
                        self.stats['updated'] += 1
                    else:
                        # æ–°å¢
                        annotation = Annotation(
                            model_id=model_id,
                            annotated=metadata['annotated'],
                            uid=metadata['uid'],
                            score=metadata['score'],
                            data=business_data
                        )
                        session.add(annotation)
                        self.stats['imported'] += 1
                    
                    # æ‰¹é‡æäº¤
                    if idx % batch_size == 0:
                        session.commit()
                        print(f"  å·²å¤„ç† {idx} æ¡...")
                
                except Exception as e:
                    self.stats['errors'] += 1
                    if self.stats['errors'] <= 5:
                        print(f"âš ï¸  ç¬¬ {idx} æ¡é”™è¯¯: {e}")
            
            session.commit()
            
            # æ‰“å°ç»Ÿè®¡
            print(f"\n{'='*60}")
            print(f"âœ… å¯¼å…¥å®Œæˆï¼")
            print(f"{'='*60}")
            print(f"ğŸ“Š ç»Ÿè®¡:")
            print(f"  - æ–°å¢: {self.stats['imported']} æ¡")
            print(f"  - æ›´æ–°: {self.stats['updated']} æ¡")
            print(f"  - é”™è¯¯: {self.stats['errors']} æ¡")
            print(f"{'='*60}\n")
            
        except Exception as e:
            session.rollback()
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            raise
        finally:
            session.close()


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    print("\n" + "="*70)
    print("âš ï¸  æ³¨æ„ï¼šæ­¤å¯¼å…¥å™¨å·²è¿‡æ—¶")
    print("="*70)
    print("æ¨èä½¿ç”¨é€šç”¨å¯¼å…¥å™¨ï¼špython -m importers.generic_importer --task annotation")
    print("é€šç”¨å¯¼å…¥å™¨æ”¯æŒæ‰€æœ‰ä»»åŠ¡ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§ï¼Œç»´æŠ¤æ›´ç®€å•")
    print("="*70 + "\n")
    
    parser = argparse.ArgumentParser(description='å¯¼å…¥ç‰©ä½“å±æ€§æ ‡æ³¨æ•°æ®')
    
    default_source = os.path.join(project_root, 'merged_attributes.jsonl')
    default_db = os.path.join(project_root, 'databases/annotation.db')
    
    parser.add_argument('--source', '-s', type=str, default=default_source,
                       help=f'æ•°æ®æºæ–‡ä»¶ï¼ˆé»˜è®¤: merged_attributes.jsonlï¼‰')
    parser.add_argument('--db', '-d', type=str, default=default_db,
                       help=f'æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤: databases/annotation.dbï¼‰')
    parser.add_argument('--clean', '-c', action='store_true',
                       help='æ¸…ç©ºæ•°æ®åº“åå¯¼å…¥')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¯¼å…¥å™¨å¹¶æ‰§è¡Œ
    importer = AnnotationImporter()
    importer.import_to_db(
        source=args.source,
        db_path=args.db,
        clean=args.clean
    )
    
    print(f"âœ… å¯ä»¥è¿è¡Œ: python src/main_multi.py --uid user1\n")


if __name__ == "__main__":
    main()
